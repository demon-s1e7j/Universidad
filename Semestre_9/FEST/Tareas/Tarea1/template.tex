\documentclass{report}

\input{preamble}
\input{macros}
\input{letterfonts}

\usepackage{amsthm}

\title{\Huge{Física Estadística}\\Tarea 1}
\author{\huge{Sergio Montoya Ramírez}}
\date{202112171}

\begin{document}

\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents
\pagebreak

\chapter{}

\section*{Metodología}

Para comenzar este ejercicio creo que es primero valioso que pensemos en lo que estamos haciendo. Para iniciar, lo primero que podríamos considerar al oír el enunciado es hacer uso de un conteo estricto de todas las posibilidades pues así podríamos tener los resultados simplemente contando. Sin embargo, solo necesitamos realizar un calculo para darnos cuenta que esto resultaría extremadamente ineficiente. El calculo en cuestión es el numero de posibles resultados. Sabemos que cada dado tiene 6 caras y por lo tanto por cada uno de ellos hay 6 posibilidades lo que implica que el numero total de posibles resultados es \[
6^{6} = 46656
.\] Cosa que resultaría muy difícil de hacer sin una computador (E incluso con una es considerable pensar si vale la pena el esfuerzo tomando en cuenta que podemos usar otras técnicas de conteo). Por lo tanto, vamos a utilizar las siguientes técnicas:

\begin{enumerate}
  \item Para el primer y tercer punto utilizaremos una distribución binomial donde la probabilidad no esta repartida de manera equitativa. Es decir, en esencia esto es como si se tratase de una caminata aleatoria donde las dos posibilidades son sacar un 1 o no sacar un 1. Por lo tanto, quedaría tal que \[
  p = \frac{1}{6};\ q = \frac{5}{6}
  .\] Entonces buscaríamos los resultados para $n_1 = 2$ en el primer punto y para $n_1 = 4$ en el segundo punto.
\item En este caso, aunque también podríamos realizar un ejercicio similar al hecho en los puntos previamente expuestos. Creo que lo mejor y mas fácil es enfrentar este problema con conteo. Es decir, aprovechando que sabemos cuantos casos posibles existen ($46656$) podemos entonces averiguar cuantos casos existen que cumplen el requisito de tener al menos 1 as y así dividir este numero por el de casos totales.
\end{enumerate}


\section{}

Dado que tenemos dos posibilidades podemos utilizar la distribución binomial que nos dice: \[
W_N\left( n_1 \right) = \frac{N!}{n_1!\left( N-n_1 \right)!}p^{n_1}q^{N - n_1}
.\] Donde
\begin{enumerate}
  \item $N$ es el numero de dados (Es decir $6$)
  \item $n_1$ es el numero de 1 que queremos obtener (Es decir $2$)
  \item $p$ es la posibilidad de sacar un 1 (Es decir $\frac{1}{6}$ )
  \item $q$ es la posibilidad de no sacar un 1 (Es decir  $\frac{5}{6}$ )
\end{enumerate}

Si ponemos todo en la ecuación nos queda:
\begin{align*}
  W_6\left( 2 \right) &= \frac{6!}{2!\left( 6 - 2 \right)!}\left( \frac{1}{6} \right) ^{2} \left( \frac{1}{5} \right) ^{6-2} \\
  W_6\left( 2 \right) &= \frac{\cancel{4!}\cdot 5 \cdot 6}{2!\cancel{4!}}\left( \frac{1}{6} \right) ^{2}\left( \frac{5}{6} \right) ^{4} \\
  W_6\left( 2 \right) &= \frac{5 \cdot 6}{2}\left( \frac{1}{6^2} \frac{5^{4}}{6^{4}}\right)  \\
  W_6\left( 2 \right) &= 5 \cdot 3 \left( \frac{5^{4}}{6^{6}} \right)  \\
  W_6\left( 2 \right) &= 3 \cdot \left( \frac{5^{5}}{6^{6}} \right)
.\end{align*}

Con esto, ya todo lo que nos resta es pasarlo por una calculadora. Por lo tanto el resultado es: \[
W_6\left( 2 \right) = 3 \cdot \left( \frac{5^{5}}{6^{6}} \right) = 0.20093878600823045 \approx 20\% \square
.\] 

\section{}

Para determinar cuantas posibilidades existen con que hayan lo que podemos hacer es en vez de tirar 6 dados tiramos solamente 4 pues sabemos que el resultado de los otros 2 siempre debe ser 1. De ese modo entonces la cantidad de posibilidades nos queda como: \[
6^{4} = 1296
.\] Lo cual implica que hay $1296$ con los 4 dados restantes. Sin embargo, nosotros tenemos el numero $6^{6}$ que toma en consideración el orden en el que se encuentran. Por lo tanto, necesitamos encontrar de cuantas maneras podríamos escoger 2 de esos 6 dados para que sean el 1. Esto se puede hacer con combinatoria y por lo tanto esto seria:
\begin{align*}
  \frac{6!}{2!\left( 6-2 \right)!} &= \frac{4! \cdot  5 \cdot 6}{2! 4!} \\
  &= \frac{5 \cdot 6}{2} \\ &= 5\cdot 3 \\
  &= 15
.\end{align*}

Y ahora si multiplicamos el resultado anterior y lo dividimos por la cantidad total de posibilidades nos queda:
\begin{align*}
  \frac{15 \cdot 6^{4}}{6^{6}} &= \frac{15}{6^{2}} \\
  &= \frac{15}{32} \\
  &= 0.46875 \\
  &\approx 46\%
.\end{align*}

\section{}

En este caso, volvemos a enfrentarnos al caso de una distribución binomial. Sin embargo, en esta ocasión necesitamos que salgan exactamente 4 dados con 1 (2 ases). Por lo tanto, tenemos las siguientes condiciones: \[
W_N\left( n_1 \right) = \frac{N!}{n_1!\left( N-n_1 \right)!}p^{n_1}q^{N - n_1}
.\] Donde
\begin{enumerate}
  \item $N$ es el numero de dados (Es decir $6$)
  \item $n_1$ es el numero de 1 que queremos obtener (Es decir $4$)
  \item $p$ es la posibilidad de sacar un 1 (Es decir $\frac{1}{6}$ )
  \item $q$ es la posibilidad de no sacar un 1 (Es decir  $\frac{5}{6}$ )
\end{enumerate}

Con lo cual si ponemos todo en la ecuación queda:

\begin{align*}
  W_6\left( 4 \right) &= \frac{6!}{4!\left( 6 - 4 \right)!}\left( \frac{1}{6} \right) ^{4} \left( \frac{1}{5} \right) ^{6-4} \\
  W_6\left( 4 \right) &= \frac{\cancel{4!} \cdot 5 \cdot 6}{\cancel{4!}2!}\left( \frac{1}{6} \right)^{4}\left( \frac{5}{6} \right)^{2} \\
  W_6\left( 4 \right) &= \frac{5\cdot 6}{2}\left( \frac{1}{6^{4}}\frac{5^2}{6^2} \right)  \\
  W_6\left( 4 \right) &= 5\cdot 3 \left( \frac{5^2}{6^{6}} \right)  \\
  W_6\left( 4 \right) &= 3\cdot \left( \frac{5^{3}}{6^{6}} \right)  \\
.\end{align*}

Con lo cual lo podemos pasar por una calculadora y nos da como resultado: \[
W_6\left( 4 \right) = 3 \cdot \left( \frac{5^{3}}{6^{6}} \right) = 0.008037551440329218 \approx 0.8\% \square
.\] 

\chapter{}

\section*{Requisitos}

Para poder solucionar varios de estos puntos vamos a necesitar lo siguiente:

\thm{Teorema del Binomio}{
Es una formula que nos permite expandir un binomial: \[
  (x + y)^{n} = \sum_{k = 0}^{n} {n \choose k} x^{k}y^{n - k}
.\] 
}\label{thm:binomio}


\section{}

Para mostrar que la distribución esta normalizada lo que debemos mostrar es que \[
\sum_{n=0}^{N} W_n\left( n_1 \right) = 1 \implies \sum_{n=0}^{N} \frac{N!}{n_1!\left( N - n_1 \right)!}p^{n}q^{\left( N - n_1 \right) } = 1
.\] 

Sin embargo, esto es esencialmente directo pues podemos ver que esta es en esencia una muestra del teorema \ref{thm:binomio} por lo tanto, podemos convertir esto a:
\begin{align*}
  \sum_{n=0}^{N} W_n\left( n_1 \right) &= \sum_{n=0}^{N} \frac{N!}{n_1!\left( N - n_1 \right)!}p^{n}q^{\left( N - n_1 \right) }\\
				       &= \sum_{n_1=0}^{N} {N \choose n_1} p^{n_1}q^{\left( N - n_1 \right) } \\
				       &= \left( p + q \right)^{N} \\
				       p + q &= 1 \\
				       &= 1^{N} \\
				       &= 1 \square
.\end{align*}
\section{}

En este caso partimos de la definición de valor promedio \[
\overline{u} = \sum_{i=0}^{N} \frac{p\left( u_i \right) u_i}{p\left( u_i \right) }
.\]  Ahora bien, como ya mostramos que esta formula esta normalizada sabemos que para este caso $\sum p(n_i) = 1$ por lo tanto queda \[
\overline{u} = \sum_{i=0}^{N} p\left( u_i \right) u_i
.\] Ahora con esto podemos desarrollar:
\begin{align*}
  \overline{n_1} &= \sum_{n_1=0}^{N} n_1 \cdot  W_N\left( n_1 \right) \\
  &= \sum_{n_1 = 0}^{N} n_1 \cdot  \frac{N!}{n_1!\left( N - n_{1} \right)!}p^{n_1}q^{\left( N - n_1 \right) } \\
  &= \sum_{n_1 = 1}^{N} \cancel{n_1} \cdot \frac{N!}{\left( n_1 - 1 \right)! \cancel{n_1} \left( N - n_1 \right)!}p^{n_1}q^{\left( N - n_1 \right) } \\
  &= \sum_{n_1 = 1}^{N} \frac{N!}{\left( n_1 - 1 \right)! \left( N - n_1 \right)!}p^{n_1}q^{\left( N - n_1 \right) } \\
  u &= n_1 - 1 \implies n_1 = u + 1 \\
  &= \sum_{u = 0}^{N - 1} \frac{N!}{u! \left( N - u - 1 \right)! } p^{u + 1} q^{\left( N - u - 1 \right) }\\
  &= \sum_{u = 0}^{N - 1} \frac{\left( N - 1 \right) ! N}{u! \left( \left( N - 1 \right) - u \right)!}p^{u}pq^{\left( \left( N - 1 \right) - u \right) } \\
  &= \sum_{u = 0}^{N - 1} Np \frac{\left( N - 1 \right)!}{u! \left( \left( N - 1 \right) - u \right)! }p^{u}q^{\left( \left( N - 1 \right) - u \right) } \\
  &= Np \sum_{u = 0}^{N - 1} \frac{\left( N - 1 \right)!}{u! \left( \left( N - 1 \right) - u \right)! }p^{u}q^{\left( \left( N - 1 \right) - u \right) } \\
  \left( p + q \right)^{N - 1} &= \sum_{u = 0}^{N - 1} \frac{\left( N - 1 \right)!}{u! \left( \left( N - 1 \right) - u \right)! }p^{u}q^{\left( \left( N - 1 \right) - u \right) } \text{ Por \ref{thm:binomio}} \\
  &= Np \left( p + q \right)^{N - 1} \\
  &= Np \left( 1 \right)^{N - 1} \\
  &= Np \square
.\end{align*}

\section{}

De manera similar al punto anterior debemos partir de \[
\overline{u} = \sum_{i=0}^{N} p\left( u_i \right) u_i
.\] 
Sin embargo, en este caso dado que nos preguntan por $n_2$ lo mas fácil es alterar $W_N\left( n_1 \right) $ para que ahora la variable sea $n_2$. Por lo tanto esto nos quedaría como: \[
W_N\left( n_2 \right) = \frac{N!}{n_2!\left( N - n_2 \right)!}q^{n_2}p^{N - n_2}
.\] Con esto, podemos hacer un desarrollo muy similar al punto anterior de modo tal que nos de un resultado equivalente. Es decir, nos da $Nq$.
Sin embargo, repetire aqui el desarrollo alterado de modo tal que no quede duda de donde llega este valor:
\begin{align*}
  \overline{n_2} &= \sum_{n_2=0}^{N} n_2 \cdot  W_N\left( n_2 \right) \\
  &= \sum_{n_2 = 0}^{N} n_2 \cdot  \frac{N!}{n_2!\left( N - n_2 \right)!}q^{n_2}p^{\left( N - n_2 \right) } \\
  &= \sum_{n_2 = 1}^{N} \cancel{n_2} \cdot \frac{N!}{\left( n_2 - 1 \right)! \cancel{n_2} \left( N - n_2 \right)!}q^{n_2}p^{\left( N - n_2 \right) } \\
  &= \sum_{n_2 = 1}^{N} \frac{N!}{\left( n_2 - 1 \right)! \left( N - n_2 \right)!}q^{n_2}p^{\left( N - n_2 \right) } \\
  u &= n_2 - 1 \implies n_2 = u + 1 \\
  &= \sum_{u = 0}^{N - 1} \frac{N!}{u! \left( N - u - 1 \right)! } q^{u + 1} p^{\left( N - u - 1 \right) }\\
  &= \sum_{u = 0}^{N - 1} \frac{\left( N - 1 \right) ! N}{u! \left( \left( N - 1 \right) - u \right)!}q^{u}qp^{\left( \left( N - 1 \right) - u \right) } \\
  &= \sum_{u = 0}^{N - 1} Nq \frac{\left( N - 1 \right)!}{u! \left( \left( N - 1 \right) - u \right)! }q^{u}p^{\left( \left( N - 1 \right) - u \right) } \\
  &= Nq \sum_{u = 0}^{N - 1} \frac{\left( N - 1 \right)!}{u! \left( \left( N - 1 \right) - u \right)! }q^{u}p^{\left( \left( N - 1 \right) - u \right) } \\
  \left( q + p \right)^{N - 1} &= \sum_{u = 0}^{N - 1} \frac{\left( N - 1 \right)!}{u! \left( \left( N - 1 \right) - u \right)! }q^{u}p^{\left( \left( N - 1 \right) - u \right) } \text{ por \ref{thm:binomio}} \\
  &= Nq \left( q + p \right)^{N - 1} \\
  &= Nq \left( 1 \right)^{N - 1} \\
  &= Nq \square
.\end{align*}

\section{}

Para este caso es importante notar que
\mlenma{}{Por definición se cumple que:
  \begin{align*}
    \overline{u + n} &= \overline{u} + \overline{n}
  .\end{align*}
}{}

Por lo tanto, podemos solucionar este punto como:


  \begin{align*}
    m &= n_2 - n_1\\
    \overline{m} &= \overline{n_2 - n_1} \\
    \overline{m} &= \overline{n_2} - \overline{n_1} \\
    \overline{m} &= Nq - Np \\
    \overline{m} &= N\left( q - p \right) \square
  .\end{align*}

\section{}

Para este caso vamos a desarrollar el siguiente problema: \[
\overline{\left( \Delta u \right)^2} = \sum_{u=0}^{N} P(u)\cdot \left( u - \overline{u} \right)^2
.\] lo que para nuestro caso es:
\begin{align*}
  \overline{\left( \delta n_1 \right)^2 } &= \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot \left( n_1 - \overline{n_1} \right)^2 \\
  \overline{\left( \delta n_1 \right)^2 } &= \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot \left( n_1 - Np \right)^2 \\
  \overline{\left( \delta n_1 \right)^2 } &= \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot \left( n_1^2 - 2n_1Np + \left( Np \right)^2 \right) \\
  \overline{\left( \delta n_1 \right)^2 } &= \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1^2 -\sum_{n_1 = 0}^{N} W_N\left( n_1 \right)\cdot  2n_1Np +\sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot \left( Np \right)^2
.\end{align*}

Como podemos ver cada una de estas sumas es independiente entre si por lo tanto las trataremos por separado:
\begin{enumerate}
  \item $\displaystyle\sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1^2$

    Para este caso podemos partir de notar que: \[
      n_1^2 = n_1\left( n_1 - 1 \right) + n_1
    .\] Con lo cual lo podemos sustituir y nos da:
    \begin{align*}
      \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1^2 &= \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1\left( n_1 - 1\right) + \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1
    .\end{align*}

    Donde el segundo termino podemos notar que es esencialmente $\overline{n_1} = Np$ por lo tanto esto se simplifica y queda como:

    \begin{align*}
      \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1^2 &= \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1\left( n_1 - 1\right) + Np
    .\end{align*}

    Ahora bien, para la primera sumatoria desarrollemos por aparte:
    \begin{align*}
      \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1\left( n_1 - 1 \right)  &= \sum_{n_1 = 0}^{N} \frac{N!}{n_1!\left( N - n_1 \right)!}p^{n_1}q^{N - n_1}\cdot n_1\left( n_1 - 1 \right)  \\
      &=  \frac{N!}{0!\left( N - 0 \right)!}p^{0}q^{N - 0}\cdot 0\left( 0 - 1 \right) + \sum_{n_1 = 1}^{N} \frac{N!}{n_1!\left( N - n_1 \right)!}p^{n_1}q^{N - n_1}\cdot n_1\left( n_1 - 1 \right)\\
      &= \sum_{n_1 = 1}^{N} \frac{N!}{n_1!\left( N - n_1 \right)!}p^{n_1}q^{N - n_1}\cdot n_1\left( n_1 - 1 \right) \\
      &= \sum_{n_1 = 1}^{N} \frac{N!}{\left( n_1 - 2 \right) !\cancel{\left( n_1 - 1 \right) }\cancel{n_1}\left( N - n_1 \right)!}p^{n_1}q^{N - n_1}\cdot \cancel{n_1}\cancel{\left( n_1 - 1 \right)} \\
      &= \sum_{n_1 = 1}^{N} \frac{N!}{\left( n_1 - 2 \right)! \left( N - n_1 \right)!}p^{n_1}q^{N - n_1} \\
      k &= n_1 - 2 \implies n_1 = k + 2 \\
      &= \sum_{k = 0}^{N} \frac{N!}{k! \left( N - \left( k + 2 \right)  \right)!}p^{k + 2}q^{N - \left( k + 2 \right) } \\
      &= \sum_{k = 0}^{N - 2} N\left( N - 1 \right) \frac{\left( N - 2 \right) !}{k! \left( \left( N - 2 \right)  - k  \right)!}p^{k}p^2q^{\left( N - 2 \right) - k } \\
      &= N\left( N - 1 \right) p^2 \sum_{k=0}^{n} \frac{\left( n - 2 \right)!}{k! \left( \left( n - 2 \right) - k \right)!}p^{k}q^{\left( n - 2 \right) - k}\\
      \left( p + q \right)^{N - 2} &= N\left( N - 1 \right) p^2 \sum_{k=0}^{n} \frac{\left( n - 2 \right)!}{k! \left( \left( n - 2 \right) - k \right)!}p^{k}q^{\left( n - 2 \right) - k}\\
      &= N\left( N - 1 \right)p^2 \left( p + q \right)^{N - 2} \\
      &= N\left( N -1 \right)p^{2} \left( 1 \right)^{N - 2} \\
      &= N\left( N - 1 \right)p^2
    .\end{align*}

    Por lo tanto, el resultado total de esta sección concreta es: \[
      \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1^2 = \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1\left( n_1 - 1\right) + \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1 = N\left( N - 1 \right)p^2 + Np
    .\] 

  \item $\displaystyle\sum_{n_1 = 0}^{N} W_N\left( n_1 \right)\cdot  2n_1Np$
    
    Para este caso, es importante notar que $2Np$ es un valor constante por lo tanto podemos sacarlo de la sumatoria lo que nos lleva a \[
    \sum_{n_1 = 0}^{N} W_N\left( n_1 \right)\cdot  2n_1Np = 2Np \sum_{n_1 = 0}^{N} W_N\left( n_1 \right)\cdot  n_1
    .\] Donde podemos notar que la sumatoria que queda es $\overline{n_1} = Np$ por lo tanto el total de esta sumatoria seria: \[
    \sum_{n_1 = 0}^{N} W_N\left( n_1 \right)\cdot  2n_1Np = 2Np \sum_{n_1 = 0}^{N} W_N\left( n_1 \right)\cdot  n_1 = 2Np\cdot Np = 2\left( Np \right)^2
    .\] 
  \item $\displaystyle\sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot \left( Np \right)^2$

    Como en el caso anterior  $\left( Np \right)^2$ es un valor constante por lo tanto podemos desarrollar de la siguiente manera:
    \begin{align*}
      \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot \left( Np \right)^2 &= \left( Np \right)^2 \sum_{n_1 = 0}^{N} W_N\left( n_1 \right)
    .\end{align*}

    Sin embargo, ya mostramos en el punto 1 que esta probabilidad esta normalizada por lo tanto esto queda como: \[
      \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot \left( Np \right)^2 = \left( Np \right)^2 \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) = \left( Np \right)^2
    .\] 
\end{enumerate}

Ahora, juntando todos los resultados anteriores tenemos:

\begin{align*}
  \overline{\left( \delta n_1 \right)^2 } &= \sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot n_1^2 -\sum_{n_1 = 0}^{N} W_N\left( n_1 \right)\cdot  2n_1Np +\sum_{n_1 = 0}^{N} W_N\left( n_1 \right) \cdot \left( Np \right)^2 \\
  &= N\left( N - 1 \right)p^2 + Np - 2\left( Np \right)^2 + \left( Np \right)^2 \\
  &= N\left( N - 1 \right) p^2 + Np - \left( Np \right)^2 \\
  &= Np\left[ \left( N - 1 \right)p + 1 - Np \right]  \\
  &= Np\left[ \cancel{Np} - p + 1 - \cancel{Np} \right]  \\
  &= Np\left[ 1 - p \right]  \\
  &= Npq \square
.\end{align*}

\chapter{}

\section{}

En este caso vamos a partir de la definición de $W_N\left( n_1 \right) $ con lo cual tenemos
\begin{align*}
  \ln\left( W_N\left( n_1 \right)  \right) &= \ln\left( \frac{N!}{n_1!\left( N - n_1 \right)!} p^{n_1}q^{N - n_1}\right) \\
  &= \ln\left( N! \right) - \ln\left( n_1!\left( N - n_1 \right)! \right) + \ln\left( p^{n_1} \right) + \ln\left( q^{N - n_1} \right)   \\
  &= \ln\left( N! \right) - \ln\left( n_1! \right) - \ln\left( \left( N - 1 \right)!  \right) + n_1\ln\left( p \right) + \left( N - n_1 \right) \ln\left( q \right)
.\end{align*}

Ahora bien, podemos hacer uso de la formula de stirling para seguir resolviendo este problema:
\thm{Formula de Stirling}{
  Para un $n$ grande se cumple que: \[
  \ln\left( n! \right) = n\ln\left( n \right) - n
  .\] 
}

  Con esto podemos desarrollar
  \begin{align*}
    W_N\left( n_1 \right) &= \ln\left( N! \right) - n_1\ln\left( n_1 \right) + n_1 - \left( N - n_1 \right) \ln\left( N - n_1 \right) - N + n_1 + n_1\ln\left( p \right) + N\ln\left( q \right) - n_1\ln\left( q \right)  \\
    W_N\left( n_1 \right) &= \ln\left( N! \right) - n_1\ln\left( n_1 \right) + n_1 - N\ln\left( N - n_1 \right) + n_1 \ln\left( N - n_1 \right) - N + n_1 + n_1\ln\left( p \right) + N\ln\left( q \right) - n_1\ln\left( q \right)  \\
   \end{align*}
   Ahora con esta formula podemos calcular su derivada
  \begin{align*}
    \frac{dW_N\left( n_1 \right) }{d n_1}&= 0 - \left( \ln\left( n_1 \right) + \frac{n_1}{n_1} \right) + 1 + \frac{N}{N - n_1} + \left( \ln\left( N - n_1 \right) - \frac{n_1}{N - n_1} \right) - 0 + 1 + \ln\left( p \right) - \ln\left( q \right)  \\
    \frac{dW_N\left( n_1 \right) }{d n_1}&= 0 - \left( \ln\left( n_1 \right) + \frac{n_1}{n_1} \right) + 1 + \frac{N - n_1}{N - n_1} + \left( \ln\left( N - n_1 \right) \right) - 0 + 1 + \ln\left( p \right) - \ln\left( q \right)  \\
    \frac{dW_N\left( n_1 \right) }{d n_1}&= -  \ln\left( n_1 \right) - 1 + 1 + 1 + \ln\left( N - n_1 \right) + 1 + \ln\left( p \right) - \ln\left( q \right)  \\
  \end{align*}

  Y con esto podemos sacar su segunda derivada
  
  \begin{align*}
    \frac{d^2W_N\left( n_1 \right) }{d n_1^2} &=  - \frac{1}{n_1} - \frac{1}{N - n_1}\\
    \frac{d^2 W_N\left( \overline{n_1} \right) }{d n_1^2} &= - \frac{1}{Np} - \frac{1}{N - Np} \\
    \frac{d^2 W_N\left( \overline{n_1} \right) }{d n_1^2} &= - \frac{1}{Np} - \frac{1}{N\left( 1 - p \right) } \\
    \frac{d^2 W_N\left( \overline{n_1} \right) }{d n_1^2} &= - \frac{1}{Np} - \frac{1}{Nq } \\
    \frac{d^2 W_N\left( \overline{n_1} \right) }{d n_1^2} &= - \frac{Nq + Np}{N^2pq}\\
  \frac{d^2 W_N\left( \overline{n_1} \right) }{d n_1^2} &= - \frac{\cancel{N}\left( p + q \right) }{N^{\cancel{2}}pq}\\
    \frac{d^2 W_N\left( \overline{n_1} \right) }{d n_1^2} &= - \frac{\left( 1\right) }{Npq}\\
    \frac{d^2 W_N\left( \overline{n_1} \right) }{d n_1^2} &= - \frac{1}{Npq}\\
    \left|  \frac{d^2 W_N\left( \overline{n_1} \right) }{d n_1^2} \right|  &=  \frac{1}{Npq}
  .\end{align*}

\section{}

En este caso, en las notas de clase nos dan una pista diciendo que partamos de la definición de normalización en continuos:
\begin{align*}
  \int_{-\infty}^{\infty} \tilde{W} e^{-\frac{1}{2}\left| B_2 \right| \eta^2} d\eta &= 1 \\
  \tilde{W} \int_{-\infty}^{\infty} e^{-\frac{1}{2}\left| B_2 \right| \eta^2} d\eta &= 1 \\
.\end{align*}

Ahora bien, debo ser honesto y decir que esta integral luego de intentarlo un par de veces la busque en Internet. Con esto encontré \href{https://es.wikipedia.org/wiki/Integral_de_Gauss}{esta} pagina de la wikipedia en donde decía: \[
\int_{-\infty}^{\infty} e^{-a \left( x + b \right)^2}dx = \sqrt{\frac{\pi}{a}} 
.\] lo cual nos solucionaba todos los problemas. Sin embargo, no me sentía cómodo siguiendo simplemente esta formula y por lo tanto seguí buscando otras soluciones hasta encontrar \href{https://youtu.be/qNfj96GcLJQ?si=QGbjJLlPIro5kT6y}{este} vídeo. Luego de verlo desarrolle por mi cuenta siguiendo su método y ademas busque otros lugares en donde desarrollaran esta integral y la mayoría lo seguía. Por lo tanto tomo la decisión de desarrollar la integral por esta misma ruta luego de entenderla y reescribirla por mi cuenta. 

Suponga \[
  G = \int_{-\infty}^{\infty} e^{-ax^2}dx
.\] 
Con lo cual podemos desarrollar \[
  G^2 = \int_{\infty}^{\infty} e^{-a\left( x^2 + y^2 \right) } dxdy
.\] Ahora bien, podemos pasar de coordenadas cartesianas a polares haciendo sustitución:
\begin{align*}
  G^2 &= \int_{0}^{2\pi}d\theta \int_{0}^{\infty} e^{-a r^2}r dr\\
  u&= ar^2 \\
  du &= 2ar dr \\
  dr &= \frac{du}{2ar} \\
  &=  \int_{0}^{2\pi}d\theta \int_{0}^{\infty} e^{-u} \frac{du}{2a}\\
  &= \left( 2\pi - 0 \right)\frac{1}{2a} \left( \left[ -e^{u} \right]_0^{\infty} \right) \\
  &= \left( 2\pi - 0 \right)\frac{-1}{2a} \left( e^{-\infty} - e^{0} \right) \\
  &= \left( 2\pi \right)\frac{-1}{2a} \left( -1 \right) \\
  &= \frac{\pi}{a}\\
  G &= \sqrt{\frac{\pi}{a}}
.\end{align*}

Con lo cual podemos sustituir en la formula que teníamos antes y nos queda:
\begin{align*}
  \tilde{W}\int_{-\infty}^{\infty} e^{-\frac{1}{2}\left| B_2 \right| \eta^2}d\eta &= 1 \\
  a &= \frac{\left| B_2 \right| }{2} \\
\tilde{W}  \sqrt{\frac{2\pi}{\left| B_2 \right| }} &= 1 \\
\tilde{W} &= \sqrt{\frac{\left| B_2 \right| }{2\pi}}  \\
\tilde{W} &= \sqrt{\frac{1}{2\pi Npq}} \square
.\end{align*}

\chapter{}

\section{}

En este caso desarrollemos la integral:
\begin{align*}
  \left< x \right> &= \int_{-\infty}^{\infty}x p\left( x \right)dx  \\
  &= \int_{-\infty}^{\infty} x \frac{1}{\sqrt{2\pi}\sigma } e^{- \frac{\left( x - \mu \right)^2 }{2\sigma^2}} \\
  &= \frac{1}{\sqrt{2\pi} \sigma} \int_{-\infty}^{\infty} x e^{- \frac{\left( x - \mu \right)^2}{2 \sigma^2}} \\
  u &= x - \mu \\
  x &= u + \mu \\
  &= \frac{1}{\sqrt{2\pi} \sigma} \int_{-\infty}^{\infty} \left( u + \mu \right) e^{- \frac{1}{2\sigma^2} u^2} du \\
  &= \frac{1}{\sqrt{2\pi} \sigma} \left( \int_{-\infty}^{\infty} u e^{-\frac{u^2}{2\sigma^2}} du + \mu \int_{-\infty}^{\infty} e^{-\frac{1}{2\sigma^2} u^2} du \right)  \\
  &= \frac{1}{\sqrt{2\pi} \sigma}\left( \int_{-\infty}^{0} ue^{-\frac{u^2}{2\sigma^2}}du + \int_{0}^{\infty} ue^{-\frac{u^2}{2\sigma^2}}du +\mu \int_{-\infty}^{\infty} e^{-\frac{1}{2\sigma^2} u^2} du \right)  \\
  &= \frac{1}{\sqrt{2\pi} \sigma}\left( - \int_{0}^{\infty} ue^{-\frac{u^2}{2\sigma^2}}du + \int_{0}^{\infty} ue^{-\frac{u^2}{2\sigma^2}}du +\mu \int_{-\infty}^{\infty} e^{-\frac{1}{2\sigma^2} u^2} du \right)  \\
  &= \frac{1}{\sqrt{2\pi} \sigma}\left(\mu \int_{-\infty}^{\infty} e^{-\frac{1}{2\sigma^2} u^2} du \right)  \\
  \int_{-\infty}^{\infty} e^{-b u^2} du &= \sqrt{\frac{\pi}{b}} \text{ Integral previa, Integral de Gauss}  \\
  &= \frac{1}{\sqrt{2\pi} \sigma}\left( \mu\sqrt{\frac{\pi}{2\sigma^2}}  \right)  \\
  &= \frac{1}{\cancel{\sqrt{2\pi} \sigma}}\left( \mu \cancel{\sqrt{2\pi}\sigma}  \right)  \\
  \left<x \right> &= \mu \square
.\end{align*}

\section{}
En este caso vamos a desarrollar:
\begin{align*}
  \left<\sigma^2 \right> &= \int_{-\infty}^{\infty}\left( x - \mu \right)^2 \frac{1}{\sqrt{2\pi} \sigma} e^{- \frac{\left( x - \mu \right)^2}{2 \sigma^2}} dx \\
  u &= \frac{x - \mu}{\sigma} \\
  \left( x - \mu \right) &= u \sigma \\
  &= \frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty}^{\infty} u^2\sigma^2 e^{- \frac{u^2}{2}} \\
  &= \frac{\sigma^2}{\sqrt{2\pi}\sigma} \int_{-\infty}^{\infty} u^2 e^{- \frac{u^2}{2}}\\
  &= \frac{\sigma}{\sqrt{2\pi}} \int_{-\infty}^{\infty} u^2 e^{- \frac{u^2}{2}}
.\end{align*}

Ahora, para la integral podemos desarrollar:
\begin{align*}
  \int_{-\infty}^{\infty} x^2 e^{- a x^2} dx &= 2\int_{0}^{\infty} x \cdot x e^{-a x^{2}} dx \\
  u &= x; dx = dx \\
  dv &= x e^{-a x^2}; v = -\frac{e^{-ax^2}}{2a} \\
  \int_{0}^{\infty} udv &= \left[ uv \right]_{0}^{\infty}  - \int_0^{\infty} vdu\\
  &=2 \left( \left[ - \frac{x e^{-ax^2}}{2a} \right]_{0}^{\infty} + \int_{0}^{\infty} \frac{e^{-ax^2}}{2a} dx \right) \\
  &= 2\left( \frac{1}{2a} \int_{0}^{\infty} e^{-ax^2} dx\right)  \\
  &= 2\left( \frac{1}{2a} \frac{1}{2}\sqrt{\frac{\pi}{a}}  \right)  \\
  &= \frac{1}{2a} \sqrt{\frac{\pi}{a}}
.\end{align*}

Que si reemplazamos todo queda:
\begin{align*}
  \frac{\sigma}{\sqrt{2\pi}} \int_{-\infty}^{\infty} u^2 e^{- \frac{u^2}{2}} &= \frac{\sigma}{\sqrt{2\pi} } \frac{1}{2a} \sqrt{\frac{\pi}{a}}  \\
  &= \frac{\sigma}{\sqrt{2\pi} } \frac{2}{2} \sqrt{2\pi}  \\
  &= \frac{\sigma \sqrt{2\pi} }{\sqrt{2\pi} } \\
  \left<\sigma^2 \right> &= \sigma
.\end{align*}

\chapter{}

\section{}

En este caso vamos a desarrollar como se nos recomienda:
\begin{align*}
  \left( 1 - p \right)^{N -n} &= \left( 1 - p \right)^{N - n} \\
  \ln\left( \left( 1 - p \right)^{N - n} \right)  &= \left( N - n \right) \ln\left( 1 - p \right)  \\
  \ln\left( \left( 1 - p \right)^{N - n} \right) &\approx \left( N - n \right) -p \\
  \ln\left( \left( 1 - p \right)^{N - n} \right) &\approx -Np \text{ Dado que } n \ll N\\
  e^{\ln\left( \left( 1 - p \right)^{N - n} \right) } &\approx e^{-Np}\\
  \left( 1 - p \right)^{N - n} &\approx e^{-Np} \square
.\end{align*}

\section{}

En este caso vamos a partir de nuevo de la definición y nos iremos aproximando poco a poco:
\begin{align*}
  \frac{N!}{n!\left( N - n \right)!}
.\end{align*}

Ahora bien, dada la definición de $x!$ sabemos que al poner $\left( N - n \right)!$ en el denominador lo que nos queda en el numerador es esencialmente la multiplicación desde $\left( N - n + 1 \right) $ hasta $N$ lo cual son exactamente  $n$ términos. Considerando que $n \ll N$ entonces podemos aproximar todos estos términos a $N$ con lo cual quedaría  $N^{n}$. En un desarrollo mas matemático, esto se vería como:
\begin{align*}
  \frac{N!}{n!\left( N - n \right)!} &= \frac{\left( N - n + 1 \right) \cdot \left( N - n + 2 \right) \cdot \ldots \left( N - n + (n - 1) \right)  \cdot \left( N \right) }{n!} \\
  \frac{N!}{n!\left( N - n \right)!} &\approx \frac{\left( N \right) \cdot \left( N  \right) \cdot \ldots \left( N  \right)  \cdot \left( N \right) }{n!} \text{ Dado que } n \ll N\\
  \frac{N!}{n!\left( N - n \right)!} &\approx \frac{N^{n}}{n!} \square
.\end{align*}

\section{}

Esta ultima parte es relativamente simple pues todo lo que debemos hacer es reemplazar lo encontrado en el punto anterior en la formula original:
\begin{align*}
  \frac{N!}{n!\left( N - n \right)!} p^{n}\left( 1 - p \right)^{N - n} &\approx \frac{N^{n}}{n!}p^n e^{-Np}\\
  & \approx \frac{\left(Np\right)^n}{n!}e^{-Np} \square
.\end{align*}

\end{document}
